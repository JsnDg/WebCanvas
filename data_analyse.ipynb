{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\tmp\\ipykernel_6420\\1393937433.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json5\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_thought_action(dict_str):\n",
    "    thought_action = {}\n",
    "    thought_match = re.search(r\"'thought':\\s*(.+?)\\s*,\\s*'action'\", dict_str)\n",
    "    action_match = re.search(r\"'action':\\s*(.+?)\\s*}\", dict_str)\n",
    "    thought = thought_match.group(1) if thought_match else None\n",
    "    thought = thought.replace(\"\\\\\", \"\").replace(\"\\\"\", \"\").replace(\"\\'\", \"\")\n",
    "    action = action_match.group(1) if action_match else None\n",
    "    action = action.replace(\"\\\\\", \"\").replace(\"\\\"\", \"\").replace(\"\\'\", \"\")\n",
    "    thought_action = {\"thought\": thought, \"action\": action}\n",
    "    return thought_action\n",
    "\n",
    "def to_dict(input_string):\n",
    "   \n",
    "    pattern = r\"('action_type'|'element_id'|'url'|'fill_text'):\\s*(<[^>]+>|\\d+|'[^']+'|\\\"[^\\\"]+\\\")\"\n",
    "    matches = re.findall(pattern, input_string)\n",
    "    extracted_fields = {}\n",
    "    for match in matches:\n",
    "        field_name, field_value = match\n",
    "        if field_value.startswith('<') and field_value.endswith('>'):\n",
    "            enum_name = field_value.split('.')[-1].strip('<> ')\n",
    "            extracted_fields[field_name.strip(\"'\")] = enum_name\n",
    "        else:\n",
    "            extracted_fields[field_name.strip(\"'\")] = field_value.strip(\"'\")\n",
    "    action = \"\"\n",
    "    if \"google_search\" in extracted_fields[\"action_type\"].lower():\n",
    "        action = \"google_search\" + \"[\" + extracted_fields[\"fill_text\"] + \"]\"\n",
    "    elif \"fill_search\" in extracted_fields[\"action_type\"].lower():\n",
    "        action = \"fill_search\" + \\\n",
    "            \"[\" + str(extracted_fields[\"element_id\"]) + \",\" + \\\n",
    "            extracted_fields[\"fill_text\"] + \"]\"\n",
    "    elif \"fill_form\" in extracted_fields[\"action_type\"].lower():\n",
    "        action = \"fill_search\" + \\\n",
    "            \"[\" + str(extracted_fields[\"element_id\"]) + \",\" + \\\n",
    "            extracted_fields[\"fill_text\"] + \"]\"\n",
    "    elif \"select_option\" in extracted_fields[\"action_type\"].lower():\n",
    "        action = \"select_option\" + \\\n",
    "            \"[\" + str(extracted_fields[\"element_id\"]) + \",\" + \\\n",
    "            extracted_fields[\"fill_text\"] + \"]\"\n",
    "    elif \"goto\" in extracted_fields[\"action_type\"].lower() and extracted_fields.get('url'):\n",
    "        action = \"goto\" + \"[\" + extracted_fields[\"url\"] + \"]\"\n",
    "    elif \"click\" in extracted_fields[\"action_type\"].lower():\n",
    "        action = \"click\" + \"[\" + str(extracted_fields[\"element_id\"]) + \"]\"\n",
    "    elif \"go_back\" in extracted_fields[\"action_type\"].lower():\n",
    "        action = \"go_back\" + \"[\" + str(extracted_fields[\"element_id\"]) + \"]\"\n",
    "    elif \"none\" in extracted_fields[\"action_type\"].lower():\n",
    "        action = \"None\"\n",
    "    return action\n",
    "\n",
    "def score_rate(score):\n",
    "    first, second = score.split(\"/\")\n",
    "    return float(first) / float(second)\n",
    "\n",
    "def parse_step_reward(dict_str):\n",
    "    score_description = {}\n",
    "    score_match = re.search(r\"'score':\\s*(.+?)\\s*,\\s*'description'\", dict_str)\n",
    "    description_match = re.search(r\"'description':\\s*(.+?)\\s*}\", dict_str)\n",
    "    score = score_match.group(1) if score_match else None\n",
    "    score = score.replace(\"\\\\\", \"\").replace(\"\\\"\", \"\").replace(\"\\'\", \"\")\n",
    "    description = description_match.group(1) if description_match else None\n",
    "    description = description.replace(\n",
    "        \"\\\\\", \"\").replace(\"\\\"\", \"\").replace(\"\\'\", \"\")\n",
    "    score_description = {\"score\": score, \"description\": description}\n",
    "    return score_description\n",
    "\n",
    "\n",
    "def process_step_reward(dict_str):\n",
    "    if dict_str.lower() == \"{}\":\n",
    "        dict_str = {}\n",
    "    elif dict_str.lower() == \"finished\":\n",
    "        dict_str = {\"score:\": 10, \"description\": \"finished\"}\n",
    "    else:\n",
    "        dict_str = parse_step_reward(dict_str)\n",
    "    return dict_str\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import json_normalize\n",
    "\n",
    "# file_path = \"csv_results/group_sample_20240429/20240429-222232_dom_gpt-3.5-turbo_dom_reward_False/1_XByRzDf1LGHZDev_fnQrj.json\"\n",
    "def write_task_result_to_df(file_path):\n",
    "    with open(file_path) as f:\n",
    "        data = json.load(f)\n",
    "    step_list = data[\"step_list\"]\n",
    "    task_name = data[\"task_name\"]\n",
    "    task_status = data[\"status\"]\n",
    "    reference_task_length = data[\"reference_task_length\"]\n",
    "    evaluate_steps = data[\"evaluate_steps\"]\n",
    "    for idx,item in enumerate(step_list):\n",
    "        for key in item:\n",
    "            step_list[idx][key] = str(step_list[idx][key])\n",
    "    data_df = json_normalize(step_list, errors='ignore')\n",
    "    return task_name,task_status,reference_task_length,evaluate_steps,data_df\n",
    "# task_name,task_status,reference_task_length,evaluate_steps,data_df = write_task_result_to_df(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_json(df):\n",
    "    df[\"step_index\"] = df[\"step_index\"].apply(lambda x: int(x))\n",
    "    df[\"trace_to_dict\"] = df[\"current_trace\"].apply(lambda x: parse_thought_action(x))\n",
    "    df[\"action_to_str\"] = df[\"execute_action\"].apply(lambda x: to_dict(x))\n",
    "    df[\"score_rate\"] = df[\"score\"].apply(lambda x: score_rate(x))\n",
    "    df[\"step_reward\"] = df[\"step_reward\"].apply(\n",
    "        lambda x: process_step_reward(x))\n",
    "    df[\"selector\"] = df[\"selector\"].fillna(\"None\")\n",
    "    df[\"match_result\"] = df[\"match_func_result\"]\n",
    "    df[\"element_value\"] = df[\"element_value\"].fillna(\"None\") \n",
    "    df[\"error\"] = df[\"error_message\"].fillna(\"None\")\n",
    "    df[\"step_url\"] = df[\"step_url\"].fillna(\"None\")\n",
    "    df_copy = df[\n",
    "        [\n",
    "            \"step_index\",\n",
    "            \"trace_to_dict\",\n",
    "            \"selector\",\n",
    "            \"action_to_str\",\n",
    "            \"score\",\n",
    "            \"score_rate\",\n",
    "            \"step_reward\",\n",
    "            \"step_url\",\n",
    "            \"match_result\",\n",
    "            \"element_value\",\n",
    "            \"error\"\n",
    "        ]\n",
    "    ]\n",
    "    def summary(x):\n",
    "        dic = {\n",
    "            \"step_index\": x[\"step_index\"],\n",
    "            \"trace_description\": x[\"trace_to_dict\"] if x[\"trace_to_dict\"] else {},\n",
    "            \"selector\": x[\"selector\"] if x[\"selector\"] != \"None\" else \"\",\n",
    "            \"element_value\":x[\"element_value\"] if x[\"element_value\"] != \"None\" else \"\",\n",
    "            \"action\": x[\"action_to_str\"] if x[\"action_to_str\"] else \"\",\n",
    "            \"task_score\": x[\"score\"],\n",
    "            \"task_score_rate\": x[\"score_rate\"],\n",
    "            \"current_reward_score_description\": x[\"step_reward\"],\n",
    "            \"url\": x[\"step_url\"],\n",
    "            \"match_result\": x[\"match_result\"],\n",
    "            \"error\":x[\"error\"] if x[\"error\"] != \"None\" else \"\"\n",
    "        }\n",
    "        # print(dic[\"match_result\"])\n",
    "        return dic\n",
    "    step_list = []\n",
    "    df_copy.apply(lambda x: step_list.append(summary(x)), axis=1)\n",
    "    return step_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "folder_path = './csv_results/group_sample_20240430/20240430-100811_dom_gpt-3.5-turbo_dom_reward_False/'\n",
    "task_list = []\n",
    "for _, filename in enumerate(os.listdir(folder_path)):\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    out_json = {}\n",
    "    task_name,task_status,reference_task_length,evaluate_steps,data_df = write_task_result_to_df(file_path)\n",
    "    out_json[\"task_id\"] = int(filename.split(\"_\")[0]) \n",
    "    out_json[\"task_name\"] = task_name\n",
    "    out_json[\"task_status\"] = task_status\n",
    "    if os.path.isfile(file_path):\n",
    "        task_step_list = write_to_json(data_df)\n",
    "        out_json[\"step_list\"] = task_step_list\n",
    "        task_list.append(out_json)\n",
    "    out_json[\"evalation\"] = evaluate_steps\n",
    "if not os.path.exists(\"./results/group_sample_20240430\"):\n",
    "    os.makedirs(\"./results/group_sample_20240430\")\n",
    "out_json_file_path = './results/group_sample_20240430/out.json'\n",
    "with open(out_json_file_path, 'w') as json_file:\n",
    "    json.dump(task_list, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           task_name        status  steps  \\\n",
      "0  View the full menu for AMC Dine-In in amctheatres  llm_finished      2   \n",
      "1  Search for used Jaguar XF with no black exteri...    step_limit     23   \n",
      "2  Browse for wall art with a price range of $25 ...    step_limit      9   \n",
      "3  Search for queen-size pillow protectors from t...    step_limit     18   \n",
      "4  Find a south african history podcast with leng...    step_limit     12   \n",
      "\n",
      "  task_score  task_score_rate  step_score  efficiency_score  \\\n",
      "0      1 / 4         0.250000         1.0          0.500000   \n",
      "1      1 / 7         0.142857         1.0          0.043478   \n",
      "2      1 / 3         0.333333         1.0          0.111111   \n",
      "3      3 / 8         0.375000         3.0          0.166667   \n",
      "4      2 / 4         0.500000         2.0          0.166667   \n",
      "\n",
      "   human_alignment_score  \n",
      "0               0.250000  \n",
      "1               0.114286  \n",
      "2               0.266667  \n",
      "3               0.300000  \n",
      "4               0.400000  \n",
      "(6, 8)\n",
      "average_step_score_rate 0.3001984126984127\n",
      "average_human_alignment_score 0.2551587301587302\n",
      "average_efficiency_score 0.33132045088566825\n",
      "step_score_rate 0.2903225806451613\n",
      "completion_rate 0.0\n"
     ]
    }
   ],
   "source": [
    "def evaluate(out_file_path):\n",
    "    def read_csv_result(file_path=out_file_path):\n",
    "        with open(file_path) as f:\n",
    "            data = json.load(f)\n",
    "        last_action_result_list = []\n",
    "        for items in data:\n",
    "            data_dic = {}\n",
    "            data_dic[\"task_id\"] = items[\"task_id\"]\n",
    "            data_dic[\"task_name\"] = items[\"task_name\"]\n",
    "            data_dic[\"status\"] = items[\"task_status\"]\n",
    "            data_dic[\"steps\"] = items[\"step_list\"][-1][\"step_index\"]\n",
    "            data_dic[\"task_score\"] = items[\"step_list\"][-1][\"task_score\"]\n",
    "            data_dic[\"task_score_rate\"] = items[\"step_list\"][-1][\"task_score_rate\"]\n",
    "            data_dic[\"selector\"] = items[\"step_list\"][-1][\"selector\"]\n",
    "            data_dic[\"action\"] = items[\"step_list\"][-1][\"action\"]\n",
    "            data_dic[\"url\"] = items[\"step_list\"][-2][\"url\"]\n",
    "            # data_dic[\"match_result\"] = items[\"step_list\"][-1][\"match_result\"]\n",
    "            last_action_result_list.append(data_dic)\n",
    "        # result_list = sorted(data,key=lambda x: x[\"step_list\"][\"task_score_rate\"],reverse=True)\n",
    "        return last_action_result_list\n",
    "    all_data = read_csv_result()\n",
    "    df = pd.DataFrame(all_data)\n",
    "    df[\"step_score\"] = df[\"task_score\"].apply(lambda x: float(x.split(\"/\")[0]))\n",
    "    df[\"efficiency_score\"] = df[\"step_score\"] / df[\"steps\"]\n",
    "\n",
    "    def get_llm_finished(row):\n",
    "        if row[\"status\"] == \"finished\" and row[\"task_score_rate\"] < 1.0:\n",
    "            return \"llm_finished\"\n",
    "        else:\n",
    "            return row[\"status\"]\n",
    "        \n",
    "    df[\"status\"] = df.apply(get_llm_finished,axis=1)\n",
    "    \n",
    "    def get_human_alignment_score(row):\n",
    "        if row[\"status\"] == \"finished\":\n",
    "            return 1\n",
    "        elif row[\"status\"] == \"llm_finished\":\n",
    "            return row[\"task_score_rate\"]\n",
    "        elif row[\"status\"] == \"step_limit\":\n",
    "            return row[\"task_score_rate\"] * 0.8\n",
    "        \n",
    "    df['human_alignment_score'] = df.apply(get_human_alignment_score, axis=1)\n",
    "\n",
    "    df_evaluate = df[[\"task_name\",\"status\",\"steps\",\"task_score\",\"task_score_rate\",\"step_score\",\"efficiency_score\",\"human_alignment_score\"]]\n",
    "\n",
    "    def calculate_total_score(scores):\n",
    "        molecular_sum = sum(float(x.split('/')[0]) for x in scores)\n",
    "        denominator_sum = sum(float(x.split('/')[1]) for x in scores)\n",
    "        final_score = molecular_sum / denominator_sum\n",
    "        return final_score\n",
    "    step_score_rate = calculate_total_score(df_evaluate['task_score'])\n",
    "\n",
    "    completion_rate = df_evaluate[df_evaluate[\"status\"] == \"finished\"].shape[0] / df_evaluate.shape[0]\n",
    "\n",
    "    print(df_evaluate.head(5))\n",
    "    print(df_evaluate.shape)\n",
    "\n",
    "    average_step_score_rate = df_evaluate[\"task_score_rate\"].mean()\n",
    "    average_human_alignment_score = df_evaluate[\"human_alignment_score\"].mean()\n",
    "    average_efficiency_score = df_evaluate[\"efficiency_score\"].mean()\n",
    "\n",
    "    print(\"average_step_score_rate\",average_step_score_rate)\n",
    "    print(\"average_human_alignment_score\",average_human_alignment_score)\n",
    "    print(\"average_efficiency_score\",average_efficiency_score)\n",
    "    print(\"step_score_rate\",step_score_rate)\n",
    "    print(\"completion_rate\",completion_rate)\n",
    "\n",
    "\n",
    "evaluate(\"./results/group_sample_20240430/out.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "webarena",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
